{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import multivariate_normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram $p(w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': 0.99,\n",
       " 'eight': 0.000925,\n",
       " 'five': 0.00089,\n",
       " 'four': 0.000886,\n",
       " 'nine': 0.000905,\n",
       " 'oh': 0.000968,\n",
       " 'one': 0.000905,\n",
       " 'seven': 0.000869,\n",
       " 'six': 0.000939,\n",
       " 'three': 0.000883,\n",
       " 'two': 0.000941,\n",
       " 'zero': 0.000889}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dict = {}\n",
    "with open('../data/unigram.txt', 'r') as unigram:\n",
    "    lines = unigram.read()\n",
    "    lines = lines.split()\n",
    "    for idx, line in enumerate(lines):\n",
    "        if idx % 2 == 0:\n",
    "            unigram_dict[line] = float(lines[idx+1])\n",
    "\n",
    "unigram_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram $p(w_t|w_{t-1})$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': {'eight': 0.012084,\n",
       "  'five': 0.011881,\n",
       "  'four': 0.009139,\n",
       "  'nine': 0.011474,\n",
       "  'oh': 0.012591,\n",
       "  'one': 0.010967,\n",
       "  'seven': 0.010967,\n",
       "  'six': 0.011779,\n",
       "  'three': 0.010865,\n",
       "  'two': 0.013201,\n",
       "  'zero': 0.010053},\n",
       " 'eight': {'<s>': 0.012287,\n",
       "  'eight': 0.005991,\n",
       "  'five': 0.005788,\n",
       "  'four': 0.0066,\n",
       "  'nine': 0.007616,\n",
       "  'oh': 0.006397,\n",
       "  'one': 0.005585,\n",
       "  'seven': 0.005483,\n",
       "  'six': 0.005991,\n",
       "  'three': 0.00589,\n",
       "  'two': 0.006803,\n",
       "  'zero': 0.006499},\n",
       " 'five': {'<s>': 0.013708,\n",
       "  'eight': 0.005788,\n",
       "  'five': 0.005686,\n",
       "  'four': 0.004569,\n",
       "  'nine': 0.005585,\n",
       "  'oh': 0.005686,\n",
       "  'one': 0.007514,\n",
       "  'seven': 0.006093,\n",
       "  'six': 0.005077,\n",
       "  'three': 0.005991,\n",
       "  'two': 0.006296,\n",
       "  'zero': 0.00589},\n",
       " 'four': {'<s>': 0.011474,\n",
       "  'eight': 0.006499,\n",
       "  'five': 0.005788,\n",
       "  'four': 0.006803,\n",
       "  'nine': 0.005382,\n",
       "  'oh': 0.006702,\n",
       "  'one': 0.00528,\n",
       "  'seven': 0.006194,\n",
       "  'six': 0.005991,\n",
       "  'three': 0.006296,\n",
       "  'two': 0.005991,\n",
       "  'zero': 0.005077},\n",
       " 'nine': {'<s>': 0.011779,\n",
       "  'eight': 0.00589,\n",
       "  'five': 0.005991,\n",
       "  'four': 0.006702,\n",
       "  'nine': 0.005483,\n",
       "  'oh': 0.006093,\n",
       "  'one': 0.006194,\n",
       "  'seven': 0.007006,\n",
       "  'six': 0.006194,\n",
       "  'three': 0.005991,\n",
       "  'two': 0.005991,\n",
       "  'zero': 0.00589},\n",
       " 'oh': {'<s>': 0.011576,\n",
       "  'eight': 0.006093,\n",
       "  'five': 0.006397,\n",
       "  'four': 0.007006,\n",
       "  'nine': 0.006397,\n",
       "  'oh': 0.014216,\n",
       "  'one': 0.008022,\n",
       "  'seven': 0.007108,\n",
       "  'six': 0.006499,\n",
       "  'three': 0.006397,\n",
       "  'two': 0.004976},\n",
       " 'one': {'<s>': 0.011779,\n",
       "  'eight': 0.0066,\n",
       "  'five': 0.005991,\n",
       "  'four': 0.006296,\n",
       "  'nine': 0.006499,\n",
       "  'oh': 0.005788,\n",
       "  'one': 0.005382,\n",
       "  'seven': 0.004874,\n",
       "  'six': 0.006093,\n",
       "  'three': 0.006499,\n",
       "  'two': 0.007311,\n",
       "  'zero': 0.006093},\n",
       " 'seven': {'<s>': 0.009951,\n",
       "  'eight': 0.0066,\n",
       "  'five': 0.006093,\n",
       "  'four': 0.005686,\n",
       "  'nine': 0.006397,\n",
       "  'oh': 0.006905,\n",
       "  'one': 0.006093,\n",
       "  'seven': 0.005788,\n",
       "  'six': 0.005686,\n",
       "  'three': 0.005788,\n",
       "  'two': 0.005991,\n",
       "  'zero': 0.005077},\n",
       " 'six': {'<s>': 0.011271,\n",
       "  'eight': 0.007108,\n",
       "  'five': 0.006905,\n",
       "  'four': 0.006702,\n",
       "  'nine': 0.006093,\n",
       "  'oh': 0.00589,\n",
       "  'one': 0.00721,\n",
       "  'seven': 0.00589,\n",
       "  'six': 0.006803,\n",
       "  'three': 0.005483,\n",
       "  'two': 0.00589,\n",
       "  'zero': 0.006905},\n",
       " 'three': {'<s>': 0.010561,\n",
       "  'eight': 0.006499,\n",
       "  'five': 0.006194,\n",
       "  'four': 0.00589,\n",
       "  'nine': 0.006296,\n",
       "  'oh': 0.0066,\n",
       "  'one': 0.004773,\n",
       "  'seven': 0.005382,\n",
       "  'six': 0.007108,\n",
       "  'three': 0.005382,\n",
       "  'two': 0.006194,\n",
       "  'zero': 0.006397},\n",
       " 'two': {'<s>': 0.011271,\n",
       "  'eight': 0.005686,\n",
       "  'five': 0.00589,\n",
       "  'four': 0.005788,\n",
       "  'nine': 0.006093,\n",
       "  'oh': 0.007819,\n",
       "  'one': 0.006803,\n",
       "  'seven': 0.005991,\n",
       "  'six': 0.007819,\n",
       "  'three': 0.005686,\n",
       "  'two': 0.007514,\n",
       "  'zero': 0.005991},\n",
       " 'zero': {'<s>': 0.009342,\n",
       "  'eight': 0.006093,\n",
       "  'five': 0.00528,\n",
       "  'four': 0.006296,\n",
       "  'nine': 0.00589,\n",
       "  'one': 0.005382,\n",
       "  'seven': 0.00528,\n",
       "  'six': 0.007108,\n",
       "  'three': 0.007006,\n",
       "  'two': 0.006194,\n",
       "  'zero': 0.013911}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict = {}\n",
    "with open('../data/bigram.txt', 'r') as bigram_txt:\n",
    "    for line in bigram_txt:\n",
    "        line = line.split()\n",
    "        bigram_dict[line[0]] = {}\n",
    "\n",
    "with open('../data/bigram.txt') as bigram_txt:\n",
    "    for line in bigram_txt:\n",
    "        line = line.split()\n",
    "        bigram_dict[line[0]][line[1]] = float(line[2])\n",
    "    \n",
    "bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': ['sil'],\n",
       " 'eight': ['ey', 't', 'sp'],\n",
       " 'five': ['f', 'ay', 'v', 'sp'],\n",
       " 'four': ['f', 'ao', 'r', 'sp'],\n",
       " 'nine': ['n', 'ay', 'n', 'sp'],\n",
       " 'oh': ['ow', 'sp'],\n",
       " 'one': ['w', 'ah', 'n', 'sp'],\n",
       " 'seven': ['s', 'eh', 'v', 'ah', 'n', 'sp'],\n",
       " 'six': ['s', 'ih', 'k', 's', 'sp'],\n",
       " 'three': ['th', 'r', 'iy', 'sp'],\n",
       " 'two': ['t', 'uw', 'sp'],\n",
       " 'zero': [['z', 'ih', 'r', 'ow', 'sp'], ['z', 'iy', 'r', 'ow', 'sp']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_dict = {}\n",
    "with open(\"../data/dictionary.txt\") as dict_txt:\n",
    "    for line in dict_txt:\n",
    "        line = line.split()\n",
    "        phonemes = []\n",
    "        word = line[0]\n",
    "        for i in range(1, len(line)):\n",
    "            phonemes.append(line[i])\n",
    "        \n",
    "        if(word in phoneme_dict.keys()):\n",
    "            phoneme_dict[word] = [phoneme_dict[word], phonemes]\n",
    "        else:\n",
    "            phoneme_dict[word] = phonemes\n",
    "phoneme_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM\n",
    "\n",
    "* NUMMIXES = Number of Mixture (Multivariate Gaussian Distribution with dim=39)\n",
    "* MIXTURE Value = Weight of each Multivariate normal\n",
    "* MEAN, VARIANCE = both length 39, features assumed to be independent\n",
    "* GCONST : Gaussian Distribution const (not sure)\n",
    "* TRANSP : transposition probability = 5*5 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emission probability: $ P(o|X) = \\sum w_i p_i(X) \\ \\ where\\ X \\sim N(\\mu_i, \\sum_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmm_dict = {}\n",
    "hmm_txt = open(\"../data/hmm.txt\")\n",
    "num_state = 3 # phoneme당 state 3개.. 'sp' 는 1개\n",
    "for idx in range(21):  # 21: Phoneme 의 갯수\n",
    "    pronun_word = hmm_txt.readline().split('\"')[1]\n",
    "    hmm_dict[pronun_word] = {}\n",
    "   \n",
    "    hmm_txt.readline()\n",
    "    \n",
    "    Numstates = hmm_txt.readline().split()\n",
    "    hmm_dict[pronun_word][Numstates[0]] = Numstates[1]\n",
    "    \n",
    "    if idx==20:\n",
    "        num_state = 1\n",
    "    \n",
    "    for st_idx in range(num_state):\n",
    "        #state number\n",
    "        state = hmm_txt.readline().split()[1]\n",
    "        hmm_dict[pronun_word][state] = {}\n",
    "        \n",
    "        \n",
    "        Num_Mixes = hmm_txt.readline().split()\n",
    "        hmm_dict[pronun_word][state][Num_Mixes[0]] = Num_Mixes[1]\n",
    "        hmm_dict[pronun_word][state]['<MIXTURES>'] = {}\n",
    "        \n",
    "        for mix_idx in range(1,11):\n",
    "            \n",
    "            mixture = hmm_txt.readline().split()\n",
    "        \n",
    "            hmm_dict[pronun_word][state]['<MIXTURES>'][mixture[1]] = {}\n",
    "            hmm_dict[pronun_word][state]['<MIXTURES>'][mixture[1]][mixture[0]] = mixture[2]\n",
    "            \n",
    "            #Mean\n",
    "            mean_dim = hmm_txt.readline().split() \n",
    "            mean_num = hmm_txt.readline().split() #39개의 mean number\n",
    "            hmm_dict[pronun_word][state]['<MIXTURES>'][mixture[1]][mean_dim[0]] = mean_num\n",
    "            \n",
    "            #Variance\n",
    "            variance_dim = hmm_txt.readline().split() #input dimension = 39\n",
    "            variance_num = hmm_txt.readline().split() #39개의 variance number\n",
    "            hmm_dict[pronun_word][state]['<MIXTURES>'][mixture[1]][variance_dim[0]] = variance_num\n",
    "            \n",
    "            #GConst\n",
    "            g_const = hmm_txt.readline().split()\n",
    "            hmm_dict[pronun_word][state]['<MIXTURES>'][mixture[1]][g_const[0]] = g_const[1]\n",
    "            \n",
    "    #Transposition Probability\n",
    "    hmm_txt.readline()\n",
    "    trans_prob=[]\n",
    "    \n",
    "    #a matrix 가져오기\n",
    "    if idx != 20:\n",
    "        for trans_idx in range(1,6):\n",
    "            trans_prob.append(hmm_txt.readline().split())\n",
    "    else:\n",
    "        for trans_idx in range(1,4):\n",
    "            trans_prob.append(hmm_txt.readline().split())\n",
    "    \n",
    "    hmm_dict[pronun_word]['<TRANSP>'] = trans_prob\n",
    "    #ENDHMM\n",
    "    hmm_txt.readline()\n",
    "hmm_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': {'<MIXTURES>': {'1': {'<GCONST>': '9.197596e+001',\n",
       "    '<MEAN>': ['-1.508647e+001',\n",
       "     '1.690120e+000',\n",
       "     '-3.829488e-001',\n",
       "     '6.419236e-001',\n",
       "     '-5.065308e-001',\n",
       "     '-3.908817e-001',\n",
       "     '1.012777e+000',\n",
       "     '2.029495e+000',\n",
       "     '3.223517e+000',\n",
       "     '2.525147e+000',\n",
       "     '2.603812e+000',\n",
       "     '1.022069e+000',\n",
       "     '2.993897e+001',\n",
       "     '-2.324865e-001',\n",
       "     '4.883844e-002',\n",
       "     '1.222839e-001',\n",
       "     '9.253027e-002',\n",
       "     '6.492668e-002',\n",
       "     '5.132933e-002',\n",
       "     '-2.308269e-002',\n",
       "     '9.083389e-002',\n",
       "     '2.527888e-001',\n",
       "     '3.424749e-001',\n",
       "     '2.162057e-001',\n",
       "     '1.574734e-002',\n",
       "     '-1.576940e-001',\n",
       "     '2.806408e-001',\n",
       "     '-2.874403e-001',\n",
       "     '-7.688734e-002',\n",
       "     '-1.113549e-001',\n",
       "     '-1.495737e-001',\n",
       "     '-1.703831e-001',\n",
       "     '-1.706861e-001',\n",
       "     '-2.208022e-001',\n",
       "     '-4.280793e-001',\n",
       "     '-3.966915e-001',\n",
       "     '-3.042443e-001',\n",
       "     '-1.879792e-001',\n",
       "     '5.372433e-001'],\n",
       "    '<MIXTURE>': '1.120568e-001',\n",
       "    '<VARIANCE>': ['3.735557e+000',\n",
       "     '4.400073e+000',\n",
       "     '6.065806e+000',\n",
       "     '7.459801e+000',\n",
       "     '1.062094e+001',\n",
       "     '1.214073e+001',\n",
       "     '1.256472e+001',\n",
       "     '1.239890e+001',\n",
       "     '1.307997e+001',\n",
       "     '1.294485e+001',\n",
       "     '1.249170e+001',\n",
       "     '1.066482e+001',\n",
       "     '1.913893e+000',\n",
       "     '9.941873e-001',\n",
       "     '1.429655e+000',\n",
       "     '1.580247e+000',\n",
       "     '1.450770e+000',\n",
       "     '1.944209e+000',\n",
       "     '2.105276e+000',\n",
       "     '2.073887e+000',\n",
       "     '2.416381e+000',\n",
       "     '2.781787e+000',\n",
       "     '2.690648e+000',\n",
       "     '2.284616e+000',\n",
       "     '1.853554e+000',\n",
       "     '9.104678e-001',\n",
       "     '2.108240e-001',\n",
       "     '2.672193e-001',\n",
       "     '2.745664e-001',\n",
       "     '2.764866e-001',\n",
       "     '3.497002e-001',\n",
       "     '3.702554e-001',\n",
       "     '4.058922e-001',\n",
       "     '4.522953e-001',\n",
       "     '4.433369e-001',\n",
       "     '4.330326e-001',\n",
       "     '3.807535e-001',\n",
       "     '3.262739e-001',\n",
       "     '2.168490e-001']},\n",
       "   '10': {'<GCONST>': '1.288222e+002',\n",
       "    '<MEAN>': ['-1.086710e+001',\n",
       "     '-3.243539e+000',\n",
       "     '7.379875e-001',\n",
       "     '1.011147e+000',\n",
       "     '-8.431051e-001',\n",
       "     '-1.926444e+000',\n",
       "     '-8.855524e-001',\n",
       "     '1.803107e-001',\n",
       "     '-1.723918e+000',\n",
       "     '-1.882193e+000',\n",
       "     '-1.626679e+000',\n",
       "     '-2.261966e+000',\n",
       "     '3.924792e+001',\n",
       "     '6.456336e-002',\n",
       "     '-2.169532e-001',\n",
       "     '-1.240060e-001',\n",
       "     '-2.989888e-001',\n",
       "     '-4.679180e-001',\n",
       "     '-6.048644e-001',\n",
       "     '-7.711880e-001',\n",
       "     '-5.194431e-001',\n",
       "     '-5.173705e-001',\n",
       "     '-4.756308e-001',\n",
       "     '-4.251097e-001',\n",
       "     '-2.635758e-001',\n",
       "     '2.739297e-001',\n",
       "     '5.160765e-002',\n",
       "     '2.618803e-001',\n",
       "     '-5.800293e-002',\n",
       "     '7.248006e-003',\n",
       "     '-3.579567e-002',\n",
       "     '2.358977e-002',\n",
       "     '1.164277e-002',\n",
       "     '-6.931499e-002',\n",
       "     '2.650424e-002',\n",
       "     '1.932538e-002',\n",
       "     '8.404225e-002',\n",
       "     '1.059876e-001',\n",
       "     '-7.007308e-002'],\n",
       "    '<MIXTURE>': '7.287467e-002',\n",
       "    '<VARIANCE>': ['3.268764e+001',\n",
       "     '4.002224e+001',\n",
       "     '3.465190e+001',\n",
       "     '3.272647e+001',\n",
       "     '3.925611e+001',\n",
       "     '4.317177e+001',\n",
       "     '4.742487e+001',\n",
       "     '5.089091e+001',\n",
       "     '5.343589e+001',\n",
       "     '4.551078e+001',\n",
       "     '3.457110e+001',\n",
       "     '3.132685e+001',\n",
       "     '2.969061e+001',\n",
       "     '2.302264e+000',\n",
       "     '3.708364e+000',\n",
       "     '2.842242e+000',\n",
       "     '2.554276e+000',\n",
       "     '2.815243e+000',\n",
       "     '2.986099e+000',\n",
       "     '3.623117e+000',\n",
       "     '3.682947e+000',\n",
       "     '3.705418e+000',\n",
       "     '3.354273e+000',\n",
       "     '2.634859e+000',\n",
       "     '2.556523e+000',\n",
       "     '2.677428e+000',\n",
       "     '5.968841e-001',\n",
       "     '7.002692e-001',\n",
       "     '5.939493e-001',\n",
       "     '5.993555e-001',\n",
       "     '7.113943e-001',\n",
       "     '7.553908e-001',\n",
       "     '8.888546e-001',\n",
       "     '9.145063e-001',\n",
       "     '9.603150e-001',\n",
       "     '8.046091e-001',\n",
       "     '6.226078e-001',\n",
       "     '5.627878e-001',\n",
       "     '5.050527e-001']},\n",
       "   '2': {'<GCONST>': '1.266133e+002',\n",
       "    '<MEAN>': ['-1.077889e+001',\n",
       "     '-6.270654e-001',\n",
       "     '-2.909479e-003',\n",
       "     '1.390891e+000',\n",
       "     '-4.158812e-001',\n",
       "     '-1.179884e+000',\n",
       "     '3.097227e-002',\n",
       "     '-2.926303e-002',\n",
       "     '-1.384430e+000',\n",
       "     '-1.359822e+000',\n",
       "     '1.538198e-001',\n",
       "     '6.976689e-002',\n",
       "     '3.601051e+001',\n",
       "     '-1.249555e+000',\n",
       "     '6.370760e-001',\n",
       "     '1.170854e-001',\n",
       "     '4.886747e-001',\n",
       "     '7.410468e-001',\n",
       "     '9.808488e-001',\n",
       "     '9.748380e-001',\n",
       "     '1.018698e+000',\n",
       "     '1.513865e+000',\n",
       "     '1.321156e+000',\n",
       "     '1.064044e+000',\n",
       "     '6.488998e-001',\n",
       "     '-1.481701e+000',\n",
       "     '2.436524e-001',\n",
       "     '4.856918e-003',\n",
       "     '9.016749e-002',\n",
       "     '-1.433519e-001',\n",
       "     '-1.632484e-001',\n",
       "     '-1.410482e-001',\n",
       "     '-2.245026e-001',\n",
       "     '-2.413224e-001',\n",
       "     '-2.445467e-001',\n",
       "     '-1.547113e-001',\n",
       "     '-2.742709e-001',\n",
       "     '-2.769147e-001',\n",
       "     '4.083516e-001'],\n",
       "    '<MIXTURE>': '6.409734e-002',\n",
       "    '<VARIANCE>': ['1.858304e+001',\n",
       "     '2.801979e+001',\n",
       "     '2.963420e+001',\n",
       "     '2.921539e+001',\n",
       "     '3.731433e+001',\n",
       "     '4.219979e+001',\n",
       "     '3.682811e+001',\n",
       "     '4.186018e+001',\n",
       "     '3.833948e+001',\n",
       "     '4.066710e+001',\n",
       "     '3.285261e+001',\n",
       "     '2.687032e+001',\n",
       "     '1.822502e+001',\n",
       "     '2.318350e+000',\n",
       "     '3.548985e+000',\n",
       "     '3.492564e+000',\n",
       "     '3.152695e+000',\n",
       "     '3.665573e+000',\n",
       "     '4.015284e+000',\n",
       "     '4.094928e+000',\n",
       "     '4.760070e+000',\n",
       "     '4.453593e+000',\n",
       "     '4.172874e+000',\n",
       "     '3.235207e+000',\n",
       "     '3.184723e+000',\n",
       "     '2.165408e+000',\n",
       "     '4.965278e-001',\n",
       "     '6.061573e-001',\n",
       "     '5.816358e-001',\n",
       "     '5.816563e-001',\n",
       "     '6.463771e-001',\n",
       "     '7.597902e-001',\n",
       "     '7.654762e-001',\n",
       "     '8.285465e-001',\n",
       "     '7.640648e-001',\n",
       "     '7.726400e-001',\n",
       "     '6.530493e-001',\n",
       "     '5.298464e-001',\n",
       "     '3.766351e-001']},\n",
       "   '3': {'<GCONST>': '5.009637e+001',\n",
       "    '<MEAN>': ['-1.555396e+001',\n",
       "     '1.913356e+000',\n",
       "     '-5.519912e-001',\n",
       "     '-1.378026e-001',\n",
       "     '-1.789261e+000',\n",
       "     '-1.832161e+000',\n",
       "     '2.434016e-001',\n",
       "     '2.186806e+000',\n",
       "     '4.507039e+000',\n",
       "     '3.989011e+000',\n",
       "     '3.664312e+000',\n",
       "     '1.425463e+000',\n",
       "     '2.929212e+001',\n",
       "     '-2.480962e-002',\n",
       "     '-1.108111e-002',\n",
       "     '-7.922691e-003',\n",
       "     '5.210309e-003',\n",
       "     '1.357263e-002',\n",
       "     '1.963963e-002',\n",
       "     '2.871299e-002',\n",
       "     '3.360532e-002',\n",
       "     '5.994171e-002',\n",
       "     '5.059760e-002',\n",
       "     '4.666983e-002',\n",
       "     '2.576045e-002',\n",
       "     '-1.126865e-002',\n",
       "     '3.409747e-002',\n",
       "     '-2.133972e-002',\n",
       "     '-2.480642e-002',\n",
       "     '-5.920585e-005',\n",
       "     '2.419117e-002',\n",
       "     '4.525243e-002',\n",
       "     '-3.442755e-003',\n",
       "     '-8.093047e-002',\n",
       "     '-1.723384e-001',\n",
       "     '-1.762590e-001',\n",
       "     '-1.163213e-001',\n",
       "     '-5.844958e-002',\n",
       "     '4.042770e-002'],\n",
       "    '<MIXTURE>': '1.476907e-001',\n",
       "    '<VARIANCE>': ['1.239993e+000',\n",
       "     '1.629597e+000',\n",
       "     '2.812986e+000',\n",
       "     '3.755304e+000',\n",
       "     '4.679666e+000',\n",
       "     '5.643860e+000',\n",
       "     '7.111724e+000',\n",
       "     '7.661739e+000',\n",
       "     '7.482629e+000',\n",
       "     '7.538856e+000',\n",
       "     '7.708627e+000',\n",
       "     '7.662905e+000',\n",
       "     '1.658078e+000',\n",
       "     '1.027339e-001',\n",
       "     '2.053364e-001',\n",
       "     '3.534861e-001',\n",
       "     '4.949596e-001',\n",
       "     '6.567877e-001',\n",
       "     '7.776256e-001',\n",
       "     '9.045361e-001',\n",
       "     '9.806964e-001',\n",
       "     '1.007401e+000',\n",
       "     '1.020450e+000',\n",
       "     '9.986262e-001',\n",
       "     '8.868605e-001',\n",
       "     '4.205974e-002',\n",
       "     '2.313239e-002',\n",
       "     '4.303465e-002',\n",
       "     '6.901381e-002',\n",
       "     '9.135401e-002',\n",
       "     '1.193924e-001',\n",
       "     '1.359993e-001',\n",
       "     '1.714376e-001',\n",
       "     '1.874877e-001',\n",
       "     '1.887199e-001',\n",
       "     '1.928443e-001',\n",
       "     '1.844881e-001',\n",
       "     '1.804431e-001',\n",
       "     '9.835515e-003']},\n",
       "   '4': {'<GCONST>': '9.417375e+001',\n",
       "    '<MEAN>': ['-6.625199e+000',\n",
       "     '3.284483e+000',\n",
       "     '3.544385e+000',\n",
       "     '4.473285e+000',\n",
       "     '6.586485e-001',\n",
       "     '-1.352445e+000',\n",
       "     '5.263453e-001',\n",
       "     '-9.750085e-001',\n",
       "     '-3.075502e+000',\n",
       "     '-1.383340e+000',\n",
       "     '-1.699667e+000',\n",
       "     '-2.375106e+000',\n",
       "     '3.744431e+001',\n",
       "     '-2.027907e-001',\n",
       "     '4.435609e-001',\n",
       "     '1.728528e-001',\n",
       "     '9.651094e-002',\n",
       "     '1.015951e-002',\n",
       "     '2.293643e-002',\n",
       "     '-2.977061e-002',\n",
       "     '-7.468694e-002',\n",
       "     '7.051278e-002',\n",
       "     '2.824144e-002',\n",
       "     '3.376639e-002',\n",
       "     '-9.174522e-003',\n",
       "     '-4.250840e-001',\n",
       "     '-8.349143e-002',\n",
       "     '-2.171405e-001',\n",
       "     '-1.702517e-001',\n",
       "     '-1.218986e-001',\n",
       "     '5.833496e-002',\n",
       "     '1.639295e-001',\n",
       "     '1.082806e-001',\n",
       "     '1.096882e-001',\n",
       "     '1.106557e-001',\n",
       "     '6.233848e-004',\n",
       "     '-8.711032e-003',\n",
       "     '3.485246e-002',\n",
       "     '5.154944e-002'],\n",
       "    '<MIXTURE>': '8.617823e-002',\n",
       "    '<VARIANCE>': ['2.330583e+001',\n",
       "     '1.726968e+001',\n",
       "     '1.588396e+001',\n",
       "     '1.764315e+001',\n",
       "     '1.854679e+001',\n",
       "     '1.783752e+001',\n",
       "     '2.097764e+001',\n",
       "     '2.684039e+001',\n",
       "     '2.364976e+001',\n",
       "     '2.663755e+001',\n",
       "     '2.038176e+001',\n",
       "     '1.756557e+001',\n",
       "     '2.141823e+001',\n",
       "     '6.058473e-001',\n",
       "     '1.014592e+000',\n",
       "     '1.005048e+000',\n",
       "     '1.182304e+000',\n",
       "     '1.444046e+000',\n",
       "     '1.656511e+000',\n",
       "     '1.655973e+000',\n",
       "     '1.791564e+000',\n",
       "     '1.896220e+000',\n",
       "     '1.891460e+000',\n",
       "     '1.758979e+000',\n",
       "     '1.474711e+000',\n",
       "     '3.700764e-001',\n",
       "     '1.084883e-001',\n",
       "     '1.591297e-001',\n",
       "     '1.771375e-001',\n",
       "     '2.340133e-001',\n",
       "     '2.424017e-001',\n",
       "     '2.389624e-001',\n",
       "     '2.800415e-001',\n",
       "     '3.231710e-001',\n",
       "     '3.752961e-001',\n",
       "     '3.978224e-001',\n",
       "     '3.592032e-001',\n",
       "     '2.841555e-001',\n",
       "     '5.687786e-002']},\n",
       "   '5': {'<GCONST>': '6.375328e+001',\n",
       "    '<MEAN>': ['-1.588798e+001',\n",
       "     '8.133175e-001',\n",
       "     '-1.696476e+000',\n",
       "     '-9.787124e-001',\n",
       "     '-2.291894e+000',\n",
       "     '-2.255546e+000',\n",
       "     '-1.000926e+000',\n",
       "     '-2.944945e-001',\n",
       "     '8.708327e-001',\n",
       "     '3.320317e-001',\n",
       "     '7.897126e-001',\n",
       "     '-3.706631e-001',\n",
       "     '2.932726e+001',\n",
       "     '-1.109720e-001',\n",
       "     '-3.893131e-002',\n",
       "     '2.877667e-002',\n",
       "     '-3.383201e-002',\n",
       "     '-5.292009e-002',\n",
       "     '-2.916224e-002',\n",
       "     '-3.461630e-002',\n",
       "     '-1.612769e-002',\n",
       "     '7.711666e-002',\n",
       "     '9.326766e-002',\n",
       "     '5.268705e-002',\n",
       "     '4.608383e-002',\n",
       "     '-6.611508e-002',\n",
       "     '1.072412e-001',\n",
       "     '6.182235e-002',\n",
       "     '1.282665e-001',\n",
       "     '2.076765e-001',\n",
       "     '2.395338e-001',\n",
       "     '2.121167e-001',\n",
       "     '2.026620e-001',\n",
       "     '2.286483e-001',\n",
       "     '1.978302e-001',\n",
       "     '1.740526e-001',\n",
       "     '1.557698e-001',\n",
       "     '1.255608e-001',\n",
       "     '7.763872e-002'],\n",
       "    '<MIXTURE>': '1.005781e-001',\n",
       "    '<VARIANCE>': ['2.661772e+000',\n",
       "     '3.011134e+000',\n",
       "     '4.271091e+000',\n",
       "     '5.634263e+000',\n",
       "     '8.369627e+000',\n",
       "     '9.940325e+000',\n",
       "     '9.626945e+000',\n",
       "     '9.625044e+000',\n",
       "     '1.057712e+001',\n",
       "     '1.202029e+001',\n",
       "     '1.076801e+001',\n",
       "     '9.647687e+000',\n",
       "     '1.658078e+000',\n",
       "     '2.010857e-001',\n",
       "     '3.208274e-001',\n",
       "     '5.028622e-001',\n",
       "     '6.519573e-001',\n",
       "     '8.571452e-001',\n",
       "     '1.007254e+000',\n",
       "     '1.124430e+000',\n",
       "     '1.230264e+000',\n",
       "     '1.427145e+000',\n",
       "     '1.421600e+000',\n",
       "     '1.299283e+000',\n",
       "     '1.086579e+000',\n",
       "     '8.892536e-002',\n",
       "     '3.845678e-002',\n",
       "     '6.364425e-002',\n",
       "     '9.157782e-002',\n",
       "     '1.180245e-001',\n",
       "     '1.500940e-001',\n",
       "     '1.857170e-001',\n",
       "     '2.074015e-001',\n",
       "     '2.145599e-001',\n",
       "     '2.325066e-001',\n",
       "     '2.380522e-001',\n",
       "     '2.287805e-001',\n",
       "     '2.089977e-001',\n",
       "     '1.989496e-002']},\n",
       "   '6': {'<GCONST>': '1.069941e+002',\n",
       "    '<MEAN>': ['-8.591846e+000',\n",
       "     '-5.413634e+000',\n",
       "     '-5.238984e+000',\n",
       "     '-6.169090e-001',\n",
       "     '-6.226478e-001',\n",
       "     '-1.249242e+000',\n",
       "     '-1.006783e+000',\n",
       "     '-8.136583e-001',\n",
       "     '-3.188041e+000',\n",
       "     '-4.365757e+000',\n",
       "     '-2.446848e+000',\n",
       "     '-7.972128e-001',\n",
       "     '3.782883e+001',\n",
       "     '-4.878006e-001',\n",
       "     '6.972921e-001',\n",
       "     '-4.549070e-002',\n",
       "     '2.201521e-003',\n",
       "     '-3.600072e-002',\n",
       "     '1.240918e-001',\n",
       "     '2.688718e-001',\n",
       "     '1.135934e-001',\n",
       "     '4.270059e-001',\n",
       "     '5.562479e-001',\n",
       "     '4.185140e-001',\n",
       "     '3.243985e-001',\n",
       "     '-8.970293e-001',\n",
       "     '-1.600853e-002',\n",
       "     '4.452174e-001',\n",
       "     '5.767676e-001',\n",
       "     '2.674649e-001',\n",
       "     '1.688797e-001',\n",
       "     '8.902222e-002',\n",
       "     '9.154114e-002',\n",
       "     '4.904509e-002',\n",
       "     '6.624426e-002',\n",
       "     '1.178822e-001',\n",
       "     '2.495866e-002',\n",
       "     '-1.524479e-001',\n",
       "     '5.068344e-002'],\n",
       "    '<MIXTURE>': '9.643406e-002',\n",
       "    '<VARIANCE>': ['7.595888e+000',\n",
       "     '1.787266e+001',\n",
       "     '1.960773e+001',\n",
       "     '1.910818e+001',\n",
       "     '2.931876e+001',\n",
       "     '3.171125e+001',\n",
       "     '3.305268e+001',\n",
       "     '4.526588e+001',\n",
       "     '3.764489e+001',\n",
       "     '4.343230e+001',\n",
       "     '3.038701e+001',\n",
       "     '2.844352e+001',\n",
       "     '1.123519e+001',\n",
       "     '7.314811e-001',\n",
       "     '1.806115e+000',\n",
       "     '1.793786e+000',\n",
       "     '1.683441e+000',\n",
       "     '2.085829e+000',\n",
       "     '2.393091e+000',\n",
       "     '2.518966e+000',\n",
       "     '2.626667e+000',\n",
       "     '2.834547e+000',\n",
       "     '2.846329e+000',\n",
       "     '2.340744e+000',\n",
       "     '2.107982e+000',\n",
       "     '6.512459e-001',\n",
       "     '1.895853e-001',\n",
       "     '2.124138e-001',\n",
       "     '2.167778e-001',\n",
       "     '2.805433e-001',\n",
       "     '3.627184e-001',\n",
       "     '4.153906e-001',\n",
       "     '4.781692e-001',\n",
       "     '5.512496e-001',\n",
       "     '5.436366e-001',\n",
       "     '5.831151e-001',\n",
       "     '4.701347e-001',\n",
       "     '4.303509e-001',\n",
       "     '9.095971e-002']},\n",
       "   '7': {'<GCONST>': '6.251121e+001',\n",
       "    '<MEAN>': ['-1.654483e+001',\n",
       "     '1.056520e+000',\n",
       "     '1.746853e-002',\n",
       "     '2.385087e+000',\n",
       "     '2.370866e+000',\n",
       "     '2.468489e+000',\n",
       "     '3.042652e+000',\n",
       "     '2.776212e+000',\n",
       "     '3.094755e+000',\n",
       "     '1.978726e+000',\n",
       "     '2.364623e+000',\n",
       "     '7.894738e-001',\n",
       "     '2.880023e+001',\n",
       "     '-3.110062e-002',\n",
       "     '-1.184330e-002',\n",
       "     '-1.261902e-002',\n",
       "     '8.255625e-004',\n",
       "     '-2.126813e-003',\n",
       "     '-9.115547e-003',\n",
       "     '-2.418611e-003',\n",
       "     '-2.754321e-002',\n",
       "     '-2.129961e-002',\n",
       "     '3.065136e-003',\n",
       "     '7.764050e-003',\n",
       "     '-6.618521e-003',\n",
       "     '-1.248870e-002',\n",
       "     '5.835583e-002',\n",
       "     '-8.954854e-003',\n",
       "     '-3.937870e-002',\n",
       "     '-1.263787e-001',\n",
       "     '-2.049336e-001',\n",
       "     '-2.265066e-001',\n",
       "     '-1.885064e-001',\n",
       "     '-1.371689e-001',\n",
       "     '-1.252457e-001',\n",
       "     '-1.063908e-001',\n",
       "     '-1.095565e-001',\n",
       "     '-7.545518e-002',\n",
       "     '6.442462e-002'],\n",
       "    '<MIXTURE>': '1.273607e-001',\n",
       "    '<VARIANCE>': ['2.332503e+000',\n",
       "     '3.179730e+000',\n",
       "     '3.783787e+000',\n",
       "     '5.250627e+000',\n",
       "     '6.843032e+000',\n",
       "     '7.431461e+000',\n",
       "     '9.248105e+000',\n",
       "     '1.052924e+001',\n",
       "     '1.190223e+001',\n",
       "     '1.262860e+001',\n",
       "     '1.248431e+001',\n",
       "     '1.091289e+001',\n",
       "     '1.658078e+000',\n",
       "     '1.604415e-001',\n",
       "     '2.456330e-001',\n",
       "     '4.299746e-001',\n",
       "     '5.836110e-001',\n",
       "     '8.039726e-001',\n",
       "     '9.618056e-001',\n",
       "     '1.122929e+000',\n",
       "     '1.224751e+000',\n",
       "     '1.249591e+000',\n",
       "     '1.251106e+000',\n",
       "     '1.217385e+000',\n",
       "     '1.094817e+000',\n",
       "     '6.077952e-002',\n",
       "     '3.777215e-002',\n",
       "     '5.893112e-002',\n",
       "     '9.234082e-002',\n",
       "     '1.132144e-001',\n",
       "     '1.524133e-001',\n",
       "     '1.814835e-001',\n",
       "     '2.210988e-001',\n",
       "     '2.558381e-001',\n",
       "     '2.700696e-001',\n",
       "     '2.716219e-001',\n",
       "     '2.610784e-001',\n",
       "     '2.371919e-001',\n",
       "     '1.915238e-002']},\n",
       "   '8': {'<GCONST>': '9.777876e+001',\n",
       "    '<MEAN>': ['-8.210047e+000',\n",
       "     '-5.654166e-001',\n",
       "     '-1.309182e+000',\n",
       "     '3.071297e+000',\n",
       "     '4.356794e+000',\n",
       "     '4.440147e+000',\n",
       "     '3.648492e+000',\n",
       "     '1.206103e+000',\n",
       "     '-9.601556e-001',\n",
       "     '-2.189999e+000',\n",
       "     '-2.505700e+000',\n",
       "     '-1.684949e+000',\n",
       "     '3.651125e+001',\n",
       "     '-4.718364e-001',\n",
       "     '2.038910e-001',\n",
       "     '-6.207989e-002',\n",
       "     '-1.583998e-001',\n",
       "     '-3.109850e-001',\n",
       "     '-2.491970e-001',\n",
       "     '-4.179955e-002',\n",
       "     '3.365108e-002',\n",
       "     '2.174553e-001',\n",
       "     '2.043722e-001',\n",
       "     '1.734458e-001',\n",
       "     '3.686149e-002',\n",
       "     '-5.303068e-001',\n",
       "     '7.999672e-003',\n",
       "     '1.071576e-002',\n",
       "     '9.287748e-002',\n",
       "     '-1.735014e-001',\n",
       "     '-4.024143e-001',\n",
       "     '-5.199952e-001',\n",
       "     '-4.064009e-001',\n",
       "     '-1.963055e-001',\n",
       "     '-1.097314e-001',\n",
       "     '3.953936e-002',\n",
       "     '1.028424e-001',\n",
       "     '1.771671e-002',\n",
       "     '9.912711e-002'],\n",
       "    '<MIXTURE>': '8.429782e-002',\n",
       "    '<VARIANCE>': ['1.982792e+001',\n",
       "     '1.675152e+001',\n",
       "     '2.180575e+001',\n",
       "     '1.767536e+001',\n",
       "     '1.825793e+001',\n",
       "     '1.762783e+001',\n",
       "     '2.378583e+001',\n",
       "     '3.129387e+001',\n",
       "     '3.060837e+001',\n",
       "     '3.052661e+001',\n",
       "     '2.530112e+001',\n",
       "     '2.085518e+001',\n",
       "     '1.947128e+001',\n",
       "     '6.900406e-001',\n",
       "     '1.526444e+000',\n",
       "     '1.516246e+000',\n",
       "     '1.297220e+000',\n",
       "     '1.706973e+000',\n",
       "     '1.906381e+000',\n",
       "     '2.200467e+000',\n",
       "     '2.126113e+000',\n",
       "     '2.134693e+000',\n",
       "     '2.186452e+000',\n",
       "     '2.095384e+000',\n",
       "     '1.623537e+000',\n",
       "     '4.971346e-001',\n",
       "     '9.399509e-002',\n",
       "     '1.447370e-001',\n",
       "     '1.949298e-001',\n",
       "     '2.006448e-001',\n",
       "     '2.245317e-001',\n",
       "     '2.357592e-001',\n",
       "     '3.070770e-001',\n",
       "     '3.651741e-001',\n",
       "     '3.981290e-001',\n",
       "     '3.861934e-001',\n",
       "     '3.761393e-001',\n",
       "     '3.179956e-001',\n",
       "     '5.088150e-002']},\n",
       "   '9': {'<GCONST>': '8.897440e+001',\n",
       "    '<MEAN>': ['-9.176908e+000',\n",
       "     '-7.300356e+000',\n",
       "     '-3.056546e+000',\n",
       "     '6.593324e-001',\n",
       "     '-6.365739e-001',\n",
       "     '-4.003695e+000',\n",
       "     '-2.229952e+000',\n",
       "     '2.299973e+000',\n",
       "     '-1.756930e+000',\n",
       "     '-5.019229e+000',\n",
       "     '-2.296770e+000',\n",
       "     '-1.068153e+000',\n",
       "     '3.953609e+001',\n",
       "     '1.234045e-002',\n",
       "     '2.538291e-001',\n",
       "     '-1.495472e-001',\n",
       "     '3.700912e-002',\n",
       "     '-1.359479e-002',\n",
       "     '8.186207e-002',\n",
       "     '-1.719302e-002',\n",
       "     '-1.215811e-001',\n",
       "     '-4.588407e-002',\n",
       "     '-6.368401e-002',\n",
       "     '-1.089014e-001',\n",
       "     '-5.758253e-002',\n",
       "     '-3.308037e-001',\n",
       "     '-1.953457e-002',\n",
       "     '1.653861e-001',\n",
       "     '4.627984e-002',\n",
       "     '1.355116e-003',\n",
       "     '3.209039e-002',\n",
       "     '1.233445e-001',\n",
       "     '1.190665e-001',\n",
       "     '-5.407107e-002',\n",
       "     '-2.001504e-003',\n",
       "     '8.246853e-002',\n",
       "     '2.235624e-002',\n",
       "     '-1.407923e-002',\n",
       "     '-4.257527e-002'],\n",
       "    '<MIXTURE>': '1.084034e-001',\n",
       "    '<VARIANCE>': ['1.090289e+001',\n",
       "     '1.684076e+001',\n",
       "     '1.765445e+001',\n",
       "     '1.548063e+001',\n",
       "     '2.733032e+001',\n",
       "     '2.223961e+001',\n",
       "     '3.397771e+001',\n",
       "     '3.094973e+001',\n",
       "     '3.874288e+001',\n",
       "     '3.618841e+001',\n",
       "     '3.392469e+001',\n",
       "     '2.514441e+001',\n",
       "     '1.842030e+001',\n",
       "     '2.153202e-001',\n",
       "     '6.411844e-001',\n",
       "     '7.401204e-001',\n",
       "     '8.666822e-001',\n",
       "     '1.058835e+000',\n",
       "     '1.404375e+000',\n",
       "     '1.486006e+000',\n",
       "     '1.604049e+000',\n",
       "     '1.616696e+000',\n",
       "     '1.737833e+000',\n",
       "     '1.657702e+000',\n",
       "     '1.373252e+000',\n",
       "     '2.919626e-001',\n",
       "     '4.312901e-002',\n",
       "     '8.444227e-002',\n",
       "     '1.153599e-001',\n",
       "     '1.637184e-001',\n",
       "     '1.952138e-001',\n",
       "     '2.353790e-001',\n",
       "     '2.650411e-001',\n",
       "     '3.018110e-001',\n",
       "     '3.218806e-001',\n",
       "     '3.390913e-001',\n",
       "     '3.398690e-001',\n",
       "     '2.867173e-001',\n",
       "     '2.919492e-002']}},\n",
       "  '<NUMMIXES>': '10'},\n",
       " '<NUMSTATES>': '3',\n",
       " '<TRANSP>': [['0.000000e+000', '2.385641e-001', '7.614358e-001'],\n",
       "  ['0.000000e+000', '9.152609e-001', '8.473914e-002'],\n",
       "  ['0.000000e+000', '0.000000e+000', '0.000000e+000']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_dict['sp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    \"\"\"\n",
    "    A class with api for needed constants and matrices.\n",
    "    \"\"\"\n",
    "    def __init__(self, hmm_dict):\n",
    "        self.hmm_dict = hmm_dict\n",
    "        self.phonemes = list(self.hmm_dict.keys())\n",
    "    \n",
    "    def n_states(self, phoneme):\n",
    "        return int(self.hmm_dict[phoneme]['<NUMSTATES>'])\n",
    "    \n",
    "    def transition_prob(self, phoneme):\n",
    "        return np.array(self.hmm_dict[phoneme]['<TRANSP>']).astype(float)\n",
    "    \n",
    "    def states(self, phoneme):\n",
    "        return [int(x) for x in self.hmm_dict[phoneme] if x not in ['<NUMSTATES>', '<TRANSP>']]\n",
    "    \n",
    "    def n_mixes(self, phoneme, state):\n",
    "        return int(self.hmm_dict[phoneme][str(state)]['<NUMMIXES>'])\n",
    "    \n",
    "    def gauss_mixtures_dict(self, phoneme, state):\n",
    "        return self.hmm_dict[phoneme][str(state)]['<MIXTURES>']\n",
    "    \n",
    "    def initial_prob(self, phoneme):\n",
    "        return 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def emission_prob2(x, mixture_dict):\n",
    "        assert len(x) == 39\n",
    "        \n",
    "        prob = 0\n",
    "        for mix in mixture_dict.keys():\n",
    "            mean = np.array(mixture_dict[mix]['<MEAN>']).astype(float)\n",
    "            var = np.array(mixture_dict[mix]['<VARIANCE>']).astype(float)\n",
    "            \n",
    "            mv_norm = multivariate_normal(mean, np.eye(len(var))*var)\n",
    "            weight = float(mixture_dict[mix]['<MIXTURE>'])\n",
    "            prob += weight * mv_norm.pdf(x)\n",
    "            \n",
    "        return prob\n",
    "    \n",
    "    @staticmethod  # considering floating point precision\n",
    "    def emission_prob(x, mixture_dict):\n",
    "        assert len(x) == 39\n",
    "        \n",
    "        b = []\n",
    "        exp_sum = 0.0\n",
    "        max_b_i = 0.0\n",
    "        for mix in mixture_dict.keys():\n",
    "            mean = np.array(mixture_dict[mix]['<MEAN>']).astype(float)\n",
    "            variance = np.array(mixture_dict[mix]['<VARIANCE>']).astype(float)\n",
    "            weight = float(mixture_dict[mix]['<MIXTURE>'])\n",
    "            gconst = float(mixture_dict[mix]['<GCONST>'])\n",
    "\n",
    "            log_b_i = np.log(weight) - gconst/2 + np.sum((-0.5) * ((x-mean) ** 2) / variance)\n",
    "\n",
    "            b.append(log_b_i)\n",
    "\n",
    "        max_b_i = max(b)\n",
    "        max_idx = np.argmax(b)\n",
    "        \n",
    "        for i in range(len(b)):\n",
    "            if i != max_idx:\n",
    "                diff = b[i] - max_b_i\n",
    "                exp_sum += np.exp(diff)\n",
    "\n",
    "        return max_b_i + np.log(1+exp_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-88.1317951529 -88.1317953191\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(hmm_dict)\n",
    "mixture_dict = hmm.gauss_mixtures_dict('f', 2)\n",
    "# print(np.log(hmm.emission_prob([10.]*39, mixture_dict)), hmm.emission_prob2([20.]*39, mixture_dict))\n",
    "a = 0\n",
    "print(hmm.emission_prob([a]*39, mixture_dict), np.log(hmm.emission_prob2([a]*39, mixture_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gconst = float(mixture_dict['1']['<GCONST>'])\n",
    "mean = np.array(mixture_dict['1']['<MEAN>']).astype(float)\n",
    "var = np.array(mixture_dict['1']['<VARIANCE>']).astype(float)\n",
    "mv_norm = multivariate_normal(mean, np.eye(len(var))*var)\n",
    "\n",
    "np.abs(mv_norm.pdf(mean) - 1/((2*np.pi)**(39/2) * np.prod(np.sqrt(var)))) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get test_data (label and MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = {}\n",
    "\n",
    "for folder in os.listdir(\"../data/tst/\"):\n",
    "    for folder2 in os.listdir(\"../data/tst/{}\".format(folder)):\n",
    "        for dirpath, _, files in os.walk(\"../data/tst/{}/{}\".format(folder, folder2)):\n",
    "            for file in files:\n",
    "                with open(os.path.join(dirpath, file)) as txt:\n",
    "                    label = file.split(\".\")[0]\n",
    "                    shape = txt.readline().split()\n",
    "                    test_data[label] = {'length': int(shape[0]), 'n_features': int(shape[1])}\n",
    "                    \n",
    "                    mfcc = np.ndarray((int(shape[0]), int(shape[1])))\n",
    "                    for idx, line in enumerate(txt.readlines()):\n",
    "                        mfcc[idx] = np.array(line.split()).astype(float)\n",
    "                    \n",
    "                    test_data[label]['mfcc'] = mfcc\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isolated Word Recognition**  \n",
    "$ \\hat w = \\arg\\max_w p(w|o) $  \n",
    "$\\ \\  = \\arg\\max_w p(o|w)p(w) $  \n",
    "$\\ \\ \\simeq \\arg\\max_w \\max_q p(o, q|w)p(w) $\n",
    "\n",
    "$p(o|w)$: Acoustic model probability  \n",
    "$p(w)$: Language model probability (unigram)  \n",
    "$ o = (o_1, ... , o_T) $: observation sequence  \n",
    "$ q = (q_1, ... , q_T) $: state sequence \n",
    "\n",
    "We need to find $p(o, q|w)$ with Vierbi Algorithm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viterbi Algorithm**  \n",
    "$max_{q_0 \\sim q_t} p(q_0 \\sim q_t | o_0 \\sim o_t)$  \n",
    "$=max_{q_0 \\sim q_t} p(q_0 \\sim q_t , o_0 \\sim o_t)$  \n",
    "$=max_{q_t}\\{p(o_t|q_t)\\max_{q_{t-1}}\\{p(o_{t-1}|q_{t-1})...max_{q0}\\{p(q_0)p(o_0|q_0)p(q_1|q_0)\\}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Floating point precision) Compute it with logarithms so you can just sum up. *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$v_t(j) = \\max_{i=1}^N v_{t-1}(i)a_{ij}b_j(o_t)$  \n",
    "$v_{t-1}(j):$ previous Viterbi path probability from the previous time step  \n",
    "$a_{ij}:$ the transition probability from previous state $q_i$ to current state $q_j$  \n",
    "$b_j(o_t)(=p(o_t|q_j)):$ the state observation likelihood of the observation symbol $o_t$ given the current state j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function viterbi(observations of len T, state-graph of len N) returns best path:  \n",
    "* create a path probability matrix viterbi[N+2, T]  \n",
    "    * for each state s from 1 to N do:   ; initialization step\n",
    "        * viterbi[s, 1] $\\leftarrow a_{0,s} * b_s(o_1)$\n",
    "        * backpointer[s,1] $\\leftarrow 0$  \n",
    "    * for each timestep t from 2 to T do:  ; recursion step\n",
    "        * for each state s from 1 to N do:\n",
    "            * viterbi[s,t] $\\leftarrow \\max_{s'=1}^N viterbi[s', t-1] * a_{s',s} * b_s(o_t)$\n",
    "            * backpointer[s,t] $\\leftarrow \\arg\\max_{s'=1}^N viterbi[s', t-1] * a_{s', s}$  \n",
    "    * viterbi[q_F, T] $\\leftarrow \\max_{s=1}^N viterbi[s, T]*a_{s, q_F}$   ; termination step\n",
    "    * backpointer[q_F, T] $\\leftarrow \\arg\\max_{s=1}^N viterbi[s,T]*a_{s, q_F}$  ; termination step  \n",
    "* return the backtrace path by following backpointers to states back in time from backpointer[q_F, T]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:  \n",
    "phoneme_dict  \n",
    "test_data: labels, mfcc  \n",
    "unigram_dict  \n",
    "bigram_dict  \n",
    "hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it with one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1237743'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1237743 (289, 39)\n"
     ]
    }
   ],
   "source": [
    "labels = list(test_data.keys())\n",
    "label = labels[0]\n",
    "mfcc = test_data[label]['mfcc']\n",
    "print(label, mfcc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state1에서 들어와서 뒤로가는건 없고, 앞으로 넘어간다. 근데 제자리에 있을수도 있고. 나가면 state5를 통해서 나감."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word 가 주어져있으므로, State 5 를 통해서 나가면, 다음 Phoneme으로 넘어간다.\n",
    "['f', 'ay', 'v'] 인데, 'v'에서 다음으로 넘어가면, 다음 단어로 넘어갈 확률 $p(w2|w1)$을 구하고 다시 viterbi iteration  \n",
    "$p(q_1, q_2,... q_t, o_1,....o_t | w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 word가 주어졌다고 가정해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two models.\n",
    "1. Utterance model  \n",
    "2. Isolated word recognition model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UTTERANCE MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex) $P(one, two, o_1, o_2) = p(one)p(o_1|one) p(two|one) p(o2 | two)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(one) \\leftarrow$ unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(one|two) \\leftarrow$ bigram  \n",
    "$p(o_1|one) ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ISOLATED WORD RECOGNITON**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then how do we model $p(o_1|one)$?  \n",
    "recall that `one = ['w', 'ah', 'n', 'sp']`  \n",
    "$p(o_1|one) = p(o_{11},...o_{1,t1},...o_{1,t2},..o_{1,t3},..o_{1,t} | w_{1,1},..w_{1,t1-1}, ah_{1,t1},..., n_{1,t2},...,sp_{1,t3},..sp_{1,t})$  \n",
    "e.g. $p(ah|w) =$ transition\\ matrix(3,4) of w  \n",
    "$p(w_{1,1}) =$ transition matrix(0,1) of w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['length', 'n_features', 'mfcc'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_data['44z5938']\n",
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 39)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc = test_data['44z5938']['mfcc']\n",
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the isolated word recognition,  \n",
    "Let's assume 'mfcc' represents one word 'four'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'ao', 'r', 'sp']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_dict['four']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a viterbi initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q_1$ is given as 'f'? 이게 편한듯. 어차피 'ao'로 시작하면 답 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(O_1 | one)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.2385641 ,  0.7614358 ],\n",
       "       [ 0.        ,  0.9152609 ,  0.08473914],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob(\"sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'ao', 'r', 'sp']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_dict['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.2385641 ,  0.7614358 ],\n",
       "       [ 0.        ,  0.9152609 ,  0.08473914],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob(\"sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.858848  ,  0.0786422 ,  0.06250978,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.8590611 ,  0.1409389 ,  0.        ],\n",
       "       [ 0.        ,  0.05343336,  0.        ,  0.7964702 ,  0.1500964 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob(\"sil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phonemes = phoneme_dict['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f', 'ao', 'r', 'sp']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['<NUMSTATES>', '2', '3', '4', '<TRANSP>'])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.hmm_dict['f'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ,  1.       ,  0.       ,  0.       ,  0.       ],\n",
       "       [ 0.       ,  0.8519424,  0.1480576,  0.       ,  0.       ],\n",
       "       [ 0.       ,  0.       ,  0.703905 ,  0.296095 ,  0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       ,  0.5744837,  0.4255163],\n",
       "       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.states('f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.858848  ,  0.0786422 ,  0.06250978,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.8590611 ,  0.1409389 ,  0.        ],\n",
       "       [ 0.        ,  0.05343336,  0.        ,  0.7964702 ,  0.1500964 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob('sil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def viterbi_isolated(hmm, start, mfcc, word, phonemes):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args\n",
    "        start (int): 0<= start < T\n",
    "        mfcc (2d matrix): (time, n_features)\n",
    "        word (str): words in unigram\n",
    "        phonemes (list): sequence of phonemes in a given word\n",
    "    \n",
    "    Attributes\n",
    "        v_path: viterbi path probability with length T. We just need the max probability at T\n",
    "            and since the word is given, let's just assume that mfcc follows sequence of word phonemes.\n",
    "    \n",
    "    Returns\n",
    "        Max probability of Observation given word P(O|w), t\n",
    "    \"\"\"\n",
    "    \n",
    "    # Case1: Don't Skip sp.\n",
    "    result1 = {}\n",
    "    total_length = mfcc.shape[0]\n",
    "    v_path = []\n",
    "    phoneme_index = []\n",
    "    cur_phoneme_idx = 0\n",
    "    cur_state = 1  # Starts as state 1, states are 0~2 for sp, and 0~4 for rest.\n",
    "    \n",
    "    # init - just start with the known sequence\n",
    "    for t in range(start, total_length):  \n",
    "        cur_phoneme = phonemes[cur_phoneme_idx]\n",
    "        \n",
    "        if(t == start):\n",
    "            # We need to consider that sp can jump to next phoneme without staying.\n",
    "            log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(cur_phoneme, state=cur_state+1))\n",
    "            viterbi_prob = log_emission_prob + np.log(hmm.initial_prob(cur_phoneme))\n",
    "#             if cur_phoneme == 'sil':\n",
    "#                 print(\"Viterbi_prob: {}\".format(viterbi_prob))\n",
    "            v_path.append(viterbi_prob)  # Log for floating point precision\n",
    "            phoneme_index.append(cur_phoneme_idx)\n",
    "            continue\n",
    "        \n",
    "        # PHONEME TRANSITION\n",
    "        # Find the maximum for the next possible phoneme\n",
    "        # But the next phoneme can only be found from transition marix.\n",
    "        # If still inside the matrix, cur_phoneme_idx remains the same.\n",
    "        # Find the viterbi value with from all possible next states\n",
    "        # NEXT STATE\n",
    "        next_possible_states = np.where(hmm.transition_prob(cur_phoneme)[cur_state] > 0)[0]\n",
    "        viterbi_probs = np.zeros(shape=hmm.n_states(cur_phoneme))\n",
    "\n",
    "#         print(\"Possible states: {}\".format(next_possible_states))\n",
    "\n",
    "        for next_state in next_possible_states:\n",
    "            \n",
    "#             print(\"cur phoneme: {}\".format(cur_phoneme))\n",
    "#             print(\"cur_state: {}, next_state: {}\".format(cur_state, next_state))\n",
    "            \n",
    "            is_leaving = (next_state + 1 == hmm.states(cur_phoneme)[-1] + 1)\n",
    "            if cur_phoneme != 'sp' and is_leaving:  \n",
    "#                 print(\"CUR PHONEME: {}\".format(cur_phoneme))\n",
    "#                 print(\"CUR PHONEME IDX: {}\".format(cur_phoneme_idx))\n",
    "                if cur_phoneme == 'sil':\n",
    "                    log_emission_prob = 0\n",
    "                else:\n",
    "                    next_phoneme = phonemes[cur_phoneme_idx + 1]\n",
    "                    log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(next_phoneme, state=2))\n",
    "                \n",
    "            elif cur_phoneme == 'sp' and is_leaving:\n",
    "                # We need the next_phoneme from next word...... Shit..\n",
    "                # log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(next_phoneme, state=2))\n",
    "                log_emission_prob = 0\n",
    "            else:\n",
    "                log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(cur_phoneme, state=next_state+1))\n",
    "            \n",
    "            transition_prob = hmm.transition_prob(cur_phoneme)[cur_state][next_state]\n",
    "#             print(\"Current phoneme: {}\".format(cur_phoneme))\n",
    "#             if cur_phoneme == 'sil':\n",
    "#                 print(\"cur_state: {}\".format(cur_state))\n",
    "#                 print(\"next_state: {}\".format(next_state))\n",
    "            viterbi_probs[next_state] = v_path[t-start-1] + log_emission_prob + np.log(transition_prob)\n",
    "            # sp is optional. So we should consider cases where we skip sp.\n",
    "            # next_state + 1 is the natural number representation of state ( 1,...,5 )\n",
    "            \n",
    "            # Case where we go to 'sp'\n",
    "            # If exiting and next phoneme is 'sp' --> Add probability of going into sp    \n",
    "            if cur_phoneme != 'sp' and cur_phoneme !='sil' and is_leaving and phonemes[cur_phoneme_idx+1] == 'sp':\n",
    "                viterbi_probs[next_state] += np.log(hmm.transition_prob('sp')[0][1])\n",
    "        \n",
    "        # Update cur_state to state with maximum probability.\n",
    "#         print(\"viterbi probs: {}\".format(viterbi_probs))\n",
    "        max_prob = max([viterbi_probs[next_state] for next_state in next_possible_states])\n",
    "        cur_state = np.where(viterbi_probs == max_prob)[0][0]\n",
    "#         print(\"New state: {}\".format(cur_state))\n",
    "#         print(\"max prob: {}\".format(max_prob))\n",
    "        v_path.append(max_prob)\n",
    "        phoneme_index.append(cur_phoneme_idx)\n",
    "        \n",
    "        # Check Phoneme jump for phoneme idx\n",
    "        # We need to consider that sp can jump to next phoneme without staying.\n",
    "        # sp is optional\n",
    "        exit_state = hmm.transition_prob(cur_phoneme).shape[1] - 1\n",
    "        if cur_state == exit_state:\n",
    "#             print(\"Exit\")\n",
    "            cur_phoneme_idx += 1\n",
    "            cur_state = 1\n",
    "#             print(\"Cur phoneme: {}\".format(cur_phoneme))\n",
    "#             print(\"cur_phoneme_idx: {}\".format(cur_phoneme_idx))\n",
    "#             print(\"length of phonemes: {}\".format(phonemes))\n",
    "            if cur_phoneme_idx == len(phonemes) or t == total_length-1:\n",
    "                result1 = {'t': t, 'v_path': v_path, 'phoneme_path': [phonemes[idx] for idx in phoneme_index]}\n",
    "#                 print(\"End of word. break\")\n",
    "                break;\n",
    "        if t == total_length -1:\n",
    "            result1 = {'t': t, 'v_path': v_path, 'phoneme_path': [phonemes[idx] for idx in phoneme_index]}\n",
    "                \n",
    "    # Case2: skip sp.\n",
    "    result2 = {}\n",
    "    total_length = mfcc.shape[0]\n",
    "    v_path = []\n",
    "    phoneme_index = []\n",
    "    cur_phoneme_idx = 0\n",
    "    cur_state = 1  # Starts as state 1, states are 0~2 for sp, and 0~4 for rest.\n",
    "    \n",
    "    for t in range(start, total_length):  \n",
    "        cur_phoneme = phonemes[cur_phoneme_idx]\n",
    "        is_skip = False\n",
    "        \n",
    "        if(t == start):\n",
    "            # We need to consider that sp can jump to next phoneme without staying.\n",
    "            log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(cur_phoneme, state=cur_state+1))\n",
    "            viterbi_prob = log_emission_prob + np.log(hmm.initial_prob(cur_phoneme))\n",
    "            v_path.append(viterbi_prob)  # Log for floating point precision\n",
    "            phoneme_index.append(cur_phoneme_idx)\n",
    "            continue\n",
    "        \n",
    "        next_possible_states = np.where(hmm.transition_prob(cur_phoneme)[cur_state] > 0)[0]\n",
    "        viterbi_probs = np.zeros(shape=hmm.n_states(cur_phoneme))\n",
    "\n",
    "#         print(\"Possible states: {}\".format(next_possible_states))\n",
    "\n",
    "        for next_state in next_possible_states:\n",
    "            \n",
    "#             print(\"cur phoneme: {}\".format(cur_phoneme))\n",
    "#             print(\"cur_state: {}, next_state: {}\".format(cur_state, next_state))\n",
    "            \n",
    "            is_leaving = (next_state + 1 == hmm.states(cur_phoneme)[-1] + 1)\n",
    "#             if cur_phoneme != 'sp' and is_leaving and not phonemes[cur_phoneme_idx+1] == 'sp':\n",
    "            if is_leaving and cur_phoneme == 'sil':\n",
    "                log_emission_prob = 0\n",
    "            elif is_leaving and not phonemes[cur_phoneme_idx+1] == 'sp':\n",
    "                next_phoneme = phonemes[cur_phoneme_idx + 1]\n",
    "                log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(next_phoneme, state=2))\n",
    "            elif is_leaving and phonemes[cur_phoneme_idx+1] == 'sp':\n",
    "#                 print(\"is leaving and next is sp\")\n",
    "                # We need the next_phoneme from next word...... Shit..\n",
    "                # log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(next_phoneme, state=2))\n",
    "                log_emission_prob = 0  # Should add the probability later at bigram.\n",
    "            else:\n",
    "#                 print(\"Not leaving phoneme\")\n",
    "                log_emission_prob = hmm.emission_prob(mfcc[t], hmm.gauss_mixtures_dict(cur_phoneme, state=next_state+1))\n",
    "            \n",
    "            transition_prob = hmm.transition_prob(cur_phoneme)[cur_state][next_state]\n",
    "            viterbi_probs[next_state] = v_path[t-start-1] + log_emission_prob + np.log(transition_prob)\n",
    "            \n",
    "            # Case where we skip 'sp'\n",
    "            # If exiting and next phoneme is 'sp' --> Add probability of skipping sp \n",
    "            if cur_phoneme != 'sp' and cur_phoneme != 'sil' and is_leaving and phonemes[cur_phoneme_idx+1] == 'sp':\n",
    "#                 print(\"Next is sp and we are skipping this\")\n",
    "                viterbi_probs[next_state] += np.log(hmm.transition_prob('sp')[0][2])\n",
    "                is_skip = True\n",
    "#                 cur_phoneme_idx +=1  # To end the loop at below.        \n",
    "            \n",
    "        # Update cur_state to state with maximum probability.\n",
    "#         print(\"viterbi probs: {}\".format(viterbi_probs))\n",
    "        max_prob = max([viterbi_probs[next_state] for next_state in next_possible_states])\n",
    "        cur_state = np.where(viterbi_probs == max_prob)[0][0]\n",
    "#         print(\"New state: {}\".format(cur_state))\n",
    "#         print(\"max prob: {}\".format(max_prob))\n",
    "        v_path.append(max_prob)\n",
    "#         if cur_phoneme != 'sp' and is_leaving and phonemes[cur_phoneme_idx] =='sp':\n",
    "        phoneme_index.append(cur_phoneme_idx)\n",
    "#         else:\n",
    "#             phoneme_index.append(cur_phoneme_idx)\n",
    "        \n",
    "        # Check Phoneme jump for phoneme idx\n",
    "        # We need to consider that sp can jump to next phoneme without staying.\n",
    "        # sp is optional\n",
    "        exit_state = hmm.transition_prob(cur_phoneme).shape[1] - 1\n",
    "#         print(\"cur_phoneme index: {}\".format(cur_phoneme_idx))\n",
    "        if cur_state == exit_state or is_skip:\n",
    "#         if cur_state == exit_state or cur_phoneme_idx == len(phonemes) - 1:\n",
    "#             print(\"Exit\")\n",
    "            cur_phoneme_idx += 1\n",
    "            cur_state = 1\n",
    "#             if(cur_phoneme_idx == len(phonemes)):\n",
    "#             print(\"Cur phoneme: {}\".format(cur_phoneme))\n",
    "#             print(\"cur_phoneme_idx: {}\".format(cur_phoneme_idx))\n",
    "#             print(\"length of phonemes: {}\".format(phonemes))\n",
    "#             print(\"is_skip: {}\".format(is_skip))\n",
    "            if is_skip or cur_phoneme_idx == len(phonemes) or t == total_length-1:\n",
    "                result2 = {'t': t, 'v_path': v_path, 'phoneme_path': [phonemes[idx] for idx in phoneme_index]}\n",
    "#                 print(\"End of word. break\")\n",
    "                break;\n",
    "        if t == total_length -1:\n",
    "            result2 = {'t': t, 'v_path': v_path, 'phoneme_path': [phonemes[idx] for idx in phoneme_index]}\n",
    "            \n",
    "                \n",
    "#     print(\"results1 : {}\".format(len(result1)))\n",
    "#     print(\"results2: {}\".format(len(result2)))\n",
    "#     if result1['v_path'][-1]  > result2['v_path'][-1]:\n",
    "#         return result1\n",
    "#     else:\n",
    "#         return result2\n",
    "    return result1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continuous_recognition(hmm, mfcc, unigram_dict, bigram_dict, phoneme_dict):\n",
    "    \"\"\"\n",
    "    Returns estimated sequence of words from given mfcc.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_length = mfcc.shape[0]\n",
    "    word_path = []\n",
    "    word_list = list(phoneme_dict.keys())\n",
    "    viterbi_path = []\n",
    "    \n",
    " \n",
    "    t = 0\n",
    "    while True:\n",
    "        \n",
    "        # initial\n",
    "        if t == 0:\n",
    "            viterbi_prob = np.zeros(shape=len(word_list)+1)  # 2 zeros\n",
    "            viterbi_t = np.zeros(shape=len(word_list)+1)    # argmax_word P(word) * P(O_1|word)\n",
    "            # Find initial seq\n",
    "            for idx, word in enumerate(word_list):\n",
    "                if word == 'zero':\n",
    "                    # First zero\n",
    "                    res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word][0])\n",
    "                    p_obs_given_word = res['v_path'][-1]\n",
    "                    viterbi_t[idx] = res['t']\n",
    "                    viterbi_prob[idx] = np.log(unigram_dict[word]) + p_obs_given_word\n",
    "                    \n",
    "                    res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word][1])\n",
    "                    p_obs_given_word = res['v_path'][-1]\n",
    "                    viterbi_t[idx+1] = res['t']\n",
    "                    viterbi_prob[idx+1] = np.log(unigram_dict[word]) + p_obs_given_word\n",
    "                else:\n",
    "                    res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word])\n",
    "                    p_obs_given_word = res['v_path'][-1]\n",
    "                    viterbi_t[idx] = res['t']\n",
    "                    viterbi_prob[idx] = np.log(unigram_dict[word]) + p_obs_given_word\n",
    "            \n",
    "            word_idx = np.argmax(viterbi_prob)\n",
    "            t = int(viterbi_t[word_idx])\n",
    "#             print(t)\n",
    "            word_path.append(word_list[word_idx if word_idx != len(word_list) else word_idx-1] )\n",
    "            viterbi_path.append(max(viterbi_prob))\n",
    "            continue\n",
    "        \n",
    "        viterbi_prob = np.zeros(shape=len(word_list)+1)  # 2 zeros\n",
    "        viterbi_t = np.zeros(shape=len(word_list)+1)\n",
    "        \n",
    "#         print(t)\n",
    "        for idx, word in enumerate(word_list):\n",
    "            word_before = word_path[-1]\n",
    "            if word == 'zero':\n",
    "                # First zero\n",
    "                res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word][0])\n",
    "                p_obs_given_word = res['v_path'][-1]\n",
    "                viterbi_t[idx] = res['t']\n",
    "                \n",
    "                \n",
    "                if not (word_before in bigram_dict.keys() and word in bigram_dict[word_before].keys()):\n",
    "                    viterbi_prob[idx] = -1e30\n",
    "                else:\n",
    "                    viterbi_prob[idx] = viterbi_path[-1] + np.log(bigram_dict[word_before][word]) + p_obs_given_word\n",
    "                # Second zero\n",
    "                res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word][1])\n",
    "                p_obs_given_word = res['v_path'][-1]\n",
    "                viterbi_t[idx+1] = res['t']\n",
    "                if not (word_before in bigram_dict.keys() and word in bigram_dict[word_before].keys()):\n",
    "                    viterbi_prob[idx+1] = -1e30\n",
    "                else:\n",
    "                    viterbi_prob[idx+1] = viterbi_path[-1] + np.log(bigram_dict[word_before][word]) + p_obs_given_word\n",
    "            else:\n",
    "                res = viterbi_isolated(hmm, t, mfcc, word, phoneme_dict[word])\n",
    "                p_obs_given_word = res['v_path'][-1]\n",
    "                viterbi_t[idx] = res['t']\n",
    "                if not (word_before in bigram_dict.keys() and word in bigram_dict[word_before].keys()):\n",
    "                    viterbi_prob[idx] = -1e30\n",
    "                else:\n",
    "                    viterbi_prob[idx] = viterbi_path[-1] + np.log(bigram_dict[word_before][word]) + p_obs_given_word\n",
    "#                 if word_before == '<s>' and word == '<s>':\n",
    "#                         viterbi_prob[idx] = -1e30\n",
    "        \n",
    "        word_idx = np.argmax(viterbi_prob)\n",
    "        t = int(viterbi_t[word_idx])\n",
    "#         print(t)\n",
    "        word_path.append(word_list[word_idx if word_idx != len(word_list) else word_idx-1] )\n",
    "        \n",
    "        if(t == total_length-1):\n",
    "            break;\n",
    "    return word_path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = continuous_recognition(hmm, mfcc, unigram_dict, bigram_dict, phoneme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1237743'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_preds.append([word for word in result if word != \"<s>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'two', 'three', 'seven', 'oh', 'oh', 'four', 'three']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = ['<s>', 'two', '<s>', 'two', '<s>', 'oh', '<s>', 'two', '<s>', 'oh', '<s>', 'five', '<s>', 'oh', '<s>', 'four', '<s>', 'eight', '<s>', 'oh', '<s>', 'eight', '<s>', 'three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['two',\n",
       " 'two',\n",
       " 'oh',\n",
       " 'two',\n",
       " 'oh',\n",
       " 'five',\n",
       " 'oh',\n",
       " 'four',\n",
       " 'eight',\n",
       " 'oh',\n",
       " 'eight',\n",
       " 'three']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in res if word != \"<s>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-495986b23cf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mwords_pred\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcontinuous_recognition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mfcc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munigram_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbigram_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphoneme_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<s>\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-2c28e70afde4>\u001b[0m in \u001b[0;36mcontinuous_recognition\u001b[1;34m(hmm, mfcc, unigram_dict, bigram_dict, phoneme_dict)\u001b[0m\n\u001b[0;32m     69\u001b[0m                     \u001b[0mviterbi_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_before\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp_obs_given_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviterbi_isolated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphoneme_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[0mp_obs_given_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'v_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mviterbi_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m't'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-a72058c322bc>\u001b[0m in \u001b[0;36mviterbi_isolated\u001b[1;34m(hmm, start, mfcc, word, phonemes)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;31m#                 print(\"Not leaving phoneme\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mlog_emission_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memission_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgauss_mixtures_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_phoneme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mtransition_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransition_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_phoneme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8118ee7b7ca2>\u001b[0m in \u001b[0;36memission_prob\u001b[1;34m(x, mixture_dict)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mmax_b_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmixture_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixture_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<MEAN>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixture_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<VARIANCE>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixture_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'<MIXTURE>'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_preds = []\n",
    "labels = []\n",
    "for label in test_data.keys():\n",
    "    words_pred =  continuous_recognition(hmm, test_data[label]['mfcc'], unigram_dict, bigram_dict, phoneme_dict)\n",
    "    y_preds.append([word for word in words_pred if word != \"<s>\"])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s>': ['sil'],\n",
       " 'eight': ['ey', 't', 'sp'],\n",
       " 'five': ['f', 'ay', 'v', 'sp'],\n",
       " 'four': ['f', 'ao', 'r', 'sp'],\n",
       " 'nine': ['n', 'ay', 'n', 'sp'],\n",
       " 'oh': ['ow', 'sp'],\n",
       " 'one': ['w', 'ah', 'n', 'sp'],\n",
       " 'seven': ['s', 'eh', 'v', 'ah', 'n', 'sp'],\n",
       " 'six': ['s', 'ih', 'k', 's', 'sp'],\n",
       " 'three': ['th', 'r', 'iy', 'sp'],\n",
       " 'two': ['t', 'uw', 'sp'],\n",
       " 'zero': [['z', 'ih', 'r', 'ow', 'sp'], ['z', 'iy', 'r', 'ow', 'sp']]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_to_word(label):\n",
    "    word_dict = {'1': 'one', '2': 'two', '3': 'three', '4': 'four', '5': 'five', '6': 'six', '7': 'seven',\n",
    "                '8': 'eight', '9': 'nine', 'o': 'oh', 'z': 'zero'}\n",
    "    \n",
    "    return [word_dict[label] for label in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_word_label = [label_to_word(label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.2385641 ,  0.7614358 ],\n",
       "       [ 0.        ,  0.9152609 ,  0.08473914],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob('sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.858848  ,  0.0786422 ,  0.06250978,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.8590611 ,  0.1409389 ,  0.        ],\n",
       "       [ 0.        ,  0.05343336,  0.        ,  0.7964702 ,  0.1500964 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.transition_prob('sil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "dataset = [1, 2, 3, 4, 5, 6]\n",
    "mfccs = {1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
    "def func(hmm, mfcc):\n",
    "    return mfcc**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [func(hmm, mfccs[data]) for data in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agents = 5\n",
    "chunksize = 3\n",
    "with Pool(processes=agents) as pool:\n",
    "    function = partial(func, hmm=1)\n",
    "    res = pool.map(function, mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parallel(n_jobs=2)(delayed(func)(1, mfccs[data]) for data in dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
